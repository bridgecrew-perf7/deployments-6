---
kafka_custom_log4j: true

kafka_java_args: 
  - "{% if kafka_custom_log4j|bool %}-Dlog4j.configuration=file:{{kafka.log4j_file}}{% endif %}"

kafka_custom_java_args: ""
kafka_final_java_args: "{{ kafka_java_args + [ kafka_custom_java_args ] }}"

# Kafka already has LimitNOFILE value set in unit file, empty value will not get written to override.conf
kafka_service_overrides:
  LimitNOFILE:
  User: cp-kafka
  Group: confluent
kafka_service_environment_overrides:
  KAFKA_HEAP_OPTS: -Xmx1G -Xms1G"
  KAFKA_OPTS: "{{ kafka_final_java_args | java_arg_build_out }}"

kafka_sysctl:
  vm.swappiness: 1
  vm.dirty_background_ratio: 5
  vm.dirty_ratio: 60

kafka_sysctl_file: /etc/sysctl.conf

kafka_metrics_reporter_enabled: true

kafka_default_interal_replication_factor: "{{ [ groups['kafka'] | length, 3 ] | min }}"

kafka:
  appender_log_path: /data01/kafka/log
  kafka_appender_log_name: server.log
  kafka_appender_max_log_files: 10
  kafka_appender_log_file_size: 100MB
  state_change_appender_log_name: state-change.log
  state_change_appender_max_log_files: 10
  state_change_appender_log_file_size: 100MB
  request_appender_log_name: kafka-request.log
  request_appender_max_log_files: 10
  request_appender_log_file_size: 100MB
  cleaner_appender_log_name: log-cleaner.log
  cleaner_appender_max_log_files: 10
  cleaner_appender_log_file_size: 100MB
  controller_appender_log_name: controller.log
  controller_appender_max_log_files: 10
  controller_appender_log_file_size: 100MB
  authorizer_appender_log_name: kafka-authorizer.log
  authorizer_appender_max_log_files: 10
  authorizer_appender_log_file_size: 100MB
  metadata_appender_log_name: metadata.log
  metadata_appender_max_log_files: 10
  metadata_appender_log_file_size: 100mb
  datadir:
    - /data01/kafka/data
  properties:
    log.retention.check.interval.ms: 300000
    group.initial.rebalance.delay.ms: 3000
    log.retention.hours: 168
    log.segment.bytes: 1073741824
    num.io.threads: 16
    num.network.threads: 8
    num.partitions: 1
    num.recovery.threads.per.data.dir: 2
    offsets.topic.replication.factor: "{{kafka_default_interal_replication_factor}}"
    socket.receive.buffer.bytes: 102400
    socket.request.max.bytes: 104857600
    socket.send.buffer.bytes: 102400
    transaction.state.log.min.isr: "{{ [ 2, kafka_default_interal_replication_factor|int ] | min }}"
    transaction.state.log.replication.factor: "{{kafka_default_interal_replication_factor}}"
    zookeeper.connection.timeout.ms: 18000
    confluent.license.topic.replication.factor: "{{kafka_default_interal_replication_factor}}"
    confluent.metadata.topic.replication.factor: "{{kafka_default_interal_replication_factor}}"
    confluent.security.event.logger.exporter.kafka.topic.replicas: "{{kafka_default_interal_replication_factor}}"
    confluent.support.metrics.enable: "{{confluent.support.metrics_enabled|bool|lower}}"
    confluent.support.customer.id: "{{confluent.support.customer_id}}"
